{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msharifpour\n",
      "None\n",
      "y = 1. It's a cat picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEyCAYAAACbGke8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP2T63cb/wchDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x150097225c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "##working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "cwd=os.chdir('C:/Users/Desktop/....')\n",
    "print(cwd)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from dnn_app_utils_v2 import *\n",
    "\n",
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "### read in the datafiles \n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "# Example of a picture\n",
    "index = 200\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_x_orig shape: (209, 64, 64, 3)\n",
      "train_y shape: (1, 209)\n",
      "test_x_orig shape: (50, 64, 64, 3)\n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CONSTANTS DEFINING THE MODEL ####\n",
    "#n_x = 12288     # num_px * num_px * 3\n",
    "#n_h = 7\n",
    "#n_y = 1\n",
    "layers_dims = [12288, 20, 7, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters_deep\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])/ np.sqrt(layer_dims[l-1]) #* 0.01\n",
    "        parameters['b' + str(l)] = np.zeros(shape=(layer_dims[l], 1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 0.01465338, -0.00551871, -0.00476469, ..., -0.00475605,\n",
      "        -0.00343108,  0.00856474],\n",
      "       [ 0.00910437,  0.00207385, -0.0059909 , ...,  0.00622328,\n",
      "        -0.0044052 ,  0.00187287],\n",
      "       [-0.00321458, -0.00176345,  0.00574466, ...,  0.00742212,\n",
      "        -0.00094203, -0.00593549],\n",
      "       ..., \n",
      "       [ 0.00157639, -0.0011742 ,  0.01656117, ..., -0.00832292,\n",
      "        -0.00744053, -0.00138343],\n",
      "       [-0.00031528, -0.00376196, -0.00771457, ...,  0.02027339,\n",
      "        -0.00481399, -0.00026661],\n",
      "       [-0.01293895, -0.0100192 ,  0.00655218, ...,  0.01983405,\n",
      "         0.01387618,  0.00673519]]), 'b1': array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), 'W2': array([[ 0.20259018, -0.3085417 , -0.37746612, -0.04024358,  0.05940078,\n",
      "         0.12334556,  0.30837079,  0.04762441,  0.05302836,  0.13488878,\n",
      "         0.21657182, -0.63424146, -0.15595979,  0.10192011, -0.14986769,\n",
      "         0.05316226,  0.11436514,  0.42089156,  0.10855153, -0.21844142],\n",
      "       [ 0.24292279, -0.09271047,  0.24633566,  0.2407009 , -0.07419339,\n",
      "        -0.3140973 , -0.2378063 ,  0.38587265, -0.06125378,  0.36687191,\n",
      "        -0.03075124,  0.05074813,  0.00091604,  0.30299404,  0.10224218,\n",
      "        -0.50638283, -0.12615196,  0.17816799,  0.12788617, -0.05048083],\n",
      "       [ 0.24702443,  0.18465938, -0.08472851,  0.00682211,  0.26301448,\n",
      "        -0.16793632, -0.02160583, -0.05880307, -0.18442688, -0.08419676,\n",
      "        -0.49760503,  0.04897579,  0.05342117,  0.29123563, -0.00186282,\n",
      "        -0.06889612, -0.21222632,  0.13600029,  0.39350563, -0.15920307],\n",
      "       [ 0.13283642, -0.25233864,  0.38848562,  0.0175009 , -0.05934642,\n",
      "        -0.03763294, -0.16316537, -0.1598778 ,  0.00866664, -0.12812524,\n",
      "         0.38642985, -0.34200394,  0.00209062, -0.3747224 , -0.10733094,\n",
      "         0.15272388,  0.31735402,  0.18825871, -0.04812246, -0.12164815],\n",
      "       [-0.16524061,  0.39520346, -0.58172048,  0.15473167, -0.31326215,\n",
      "         0.03372203, -0.26115673,  0.26811862,  0.47707542, -0.1768339 ,\n",
      "        -0.14139523, -0.07722686,  0.00301682, -0.28733558,  0.0486702 ,\n",
      "        -0.07638937,  0.14664864,  0.07824474, -0.14710693, -0.3941019 ],\n",
      "       [-0.2435609 ,  0.09695246,  0.17821347,  0.20294394,  0.15516715,\n",
      "         0.26508366, -0.02808966, -0.2858965 ,  0.33423678,  0.05018149,\n",
      "        -0.23354711,  0.05059482,  0.01754097, -0.36721984,  0.16682193,\n",
      "        -0.35173   , -0.06485109, -0.30370136,  0.12028256, -0.3798758 ],\n",
      "       [ 0.20688506, -0.23459053, -0.40563652,  0.05946033,  0.0917243 ,\n",
      "        -0.32768127, -0.06881328, -0.61338784,  0.19020316, -0.1425967 ,\n",
      "         0.00564071, -0.13178665,  0.0934473 , -0.02009862,  0.09349342,\n",
      "         0.38545417,  0.33119379, -0.01765705,  0.09299516, -0.11263983]]), 'b2': array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), 'W3': array([[ 0.20930634,  0.36232545,  0.86648532, -1.07247756, -0.63999126,\n",
      "        -0.17415109, -0.15701343],\n",
      "       [-0.57997754,  0.27859535, -0.0550274 , -0.13802435,  0.23410522,\n",
      "         0.75062596, -0.34516171],\n",
      "       [ 0.16010997,  0.29166347,  0.00930796,  0.2653009 , -0.06437531,\n",
      "         0.77601349, -0.01006499],\n",
      "       [ 0.52945384,  0.5420795 ,  0.98032613, -0.05469069,  0.40245915,\n",
      "         0.00502241, -0.01420974],\n",
      "       [-0.96753783, -0.31259346,  0.52514685, -0.18815086, -0.39308334,\n",
      "         0.19497039, -0.58863959]]), 'b3': array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), 'W4': array([[-0.38423553, -0.01975151,  0.50081053,  0.89766368,  0.01869816]]), 'b4': array([[ 0.]])}\n"
     ]
    }
   ],
   "source": [
    "#parameters = initialize_parameters_deep(layers_dims)\n",
    "#print(parameters)\n",
    "#print(\"W1:\"+ str(parameters[\"W1\"].shape))\n",
    "#print(\"b1:\"+ str(parameters[\"b1\"].shape))\n",
    "#print(\"W2:\"+ str(parameters[\"W2\"].shape))\n",
    "#print(\"b2\"+ str(parameters[\"b2\"].shape))\n",
    "#print(\"W3:\"+ str(parameters[\"W3\"].shape))\n",
    "#print(\"b3:\"+ str(parameters[\"b3\"].shape))\n",
    "#print(\"W4:\"+str(parameters[\"W4\"].shape))\n",
    "#print(\"b4\"+ str(parameters[\"b4\"].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    Z = np.dot(W, A) + b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_activation_forward\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_model_forward\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    \n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev,\n",
    "                                             parameters['W' + str(l)], \n",
    "                                             parameters['b' + str(l)], \n",
    "                                             activation='relu')\n",
    "        caches.append(cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, \n",
    "                                          parameters['W' + str(L)], \n",
    "                                          parameters['b' + str(L)], \n",
    "                                          activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55893222  0.58946891  0.6117565   0.52893672  0.63110697  0.58264379\n",
      "   0.55652116  0.50163581  0.56419673  0.54498116  0.60895365  0.61711872\n",
      "   0.59900556  0.63670604  0.59071161  0.70225162  0.58916264  0.67616388\n",
      "   0.60341067  0.5743451   0.60422171  0.5768078   0.64351136  0.6600246\n",
      "   0.66032722  0.53392824  0.62094069  0.5850552   0.5801449   0.59830082\n",
      "   0.56988221  0.65897529  0.58262912  0.66742252  0.59293297  0.55231835\n",
      "   0.55894744  0.55363025  0.51792745  0.6199034   0.61203414  0.5789821\n",
      "   0.63664657  0.62345464  0.56825509  0.55307803  0.64356209  0.58381627\n",
      "   0.60326641  0.57609804  0.64855074  0.5867378   0.60971581  0.61903345\n",
      "   0.56811604  0.62251748  0.57811722  0.64820438  0.54374214  0.54747803\n",
      "   0.55780033  0.59000156  0.5946332   0.57453264  0.6150257   0.5559803\n",
      "   0.61366413  0.54613142  0.60085496  0.59572995  0.62497464  0.53557741\n",
      "   0.54208569  0.5920041   0.65792381  0.61500258  0.565305    0.5468051\n",
      "   0.57807006  0.52888615  0.60197614  0.63755142  0.56507937  0.54806831\n",
      "   0.64295276  0.57717153  0.59608934  0.52370016  0.61066064  0.59654549\n",
      "   0.59573745  0.60569559  0.56407815  0.57269491  0.60973718  0.62905899\n",
      "   0.6244567   0.64440069  0.6348519   0.57591977  0.59561025  0.57407261\n",
      "   0.59733376  0.56189289  0.54460696  0.58647771  0.59041212  0.57265208\n",
      "   0.57571182  0.59802872  0.63124934  0.61099412  0.57382992  0.62601255\n",
      "   0.61157736  0.63458159  0.63199803  0.59509295  0.51334961  0.57066161\n",
      "   0.58521003  0.62593009  0.56498649  0.62083492  0.56441094  0.59797335\n",
      "   0.56210649  0.57228769  0.61192128  0.54527731  0.58917671  0.60442373\n",
      "   0.59467726  0.55995708  0.55988589  0.6188392   0.64248448  0.61954609\n",
      "   0.5545335   0.54843377  0.60879557  0.62268624  0.58313882  0.56717344\n",
      "   0.60993092  0.56566076  0.6237143   0.63520215  0.55242176  0.60172017\n",
      "   0.60404163  0.57138968  0.6243596   0.53629523  0.54110025  0.56785935\n",
      "   0.58531782  0.53730332  0.63591402  0.5750831   0.55778995  0.5972317\n",
      "   0.61285052  0.58395752  0.6139793   0.54129581  0.58387931  0.58073024\n",
      "   0.60865655  0.65019122  0.56714266  0.6367523   0.63151519  0.60619216\n",
      "   0.60931265  0.58614388  0.58151333  0.56889906  0.6120659   0.58153074\n",
      "   0.53131274  0.5201351   0.63126516  0.61779706  0.56350986  0.55653419\n",
      "   0.58720249  0.58711161  0.55318302  0.58086175  0.63239185  0.64064046\n",
      "   0.64695035  0.60276803  0.61120197  0.50412887  0.60880844  0.5594096\n",
      "   0.5352887   0.60570374  0.59445333  0.6626829   0.55958154  0.65025883\n",
      "   0.66049912  0.5297471   0.56463917  0.54147534  0.54599962]]\n"
     ]
    }
   ],
   "source": [
    "#X= np.reshape((train_x[:,0]),(12288,1))\n",
    "#X=train_x\n",
    "#print(X.shape)\n",
    "\n",
    "#AL, caches= L_model_forward(X, parameters)\n",
    "#print(AL.shape)\n",
    "#print(X.shape[1])\n",
    "#print(caches)\n",
    "#print(len(caches[3]))\n",
    "\n",
    "#print((caches[3][0]))\n",
    "#print((caches[3][1]))\n",
    "#print(caches[0][1])\n",
    "print(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "      \n",
    "    #logprobs = np.multiply(np.log(AL), Y) + np.multiply(np.log(1-AL), 1-Y)\n",
    "    #cost = -(1/m)*np.sum(logprobs)\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(train_y.shape)\n",
    "#Y=train_y\n",
    "#Y=train_y[0,0]\n",
    "#y=y.reshape(1,1)\n",
    "#print(y.shape)\n",
    "#logprobs = np.multiply(np.log(AL), y) + np.multiply(np.log(1-AL), 1-y)\n",
    "#print(logprobs)\n",
    "#cost = -(1/1)*np.sum(logprobs)\n",
    "#print(cost)\n",
    "#compute_cost(AL, Y)\n",
    "#print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_backward\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "   \n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    #dW = (1/m)*np.dot(dZ,cache[0].T)\n",
    "    #db = (1/m)*np.sum(dZ,axis=1, keepdims=True)\n",
    "    #dA_prev = np.dot(cache[1].T, dZ)\n",
    "    \n",
    "    dW = (1/m)*np.dot(dZ, A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    #dW = np.dot(dZ, cache[0].T) / m\n",
    "    # db = np.squeeze(np.sum(dZ, axis=1, keepdims=True)) / m\n",
    "    #dA_prev = np.dot(cache[1].T, dZ)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_activation_backward\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "   \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)         \n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ =sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "       \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_model_backward\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    #print(dAL)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \n",
    "                                                                                                  activation='sigmoid')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "      \n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation='relu')\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(20, 12288)\n",
      "(20, 12288)\n",
      "(20, 1)\n",
      "(20, 1)\n",
      "(7, 20)\n",
      "(7, 20)\n",
      "(5, 7)\n",
      "(5, 7)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(12288, 209)\n",
      "(20, 209)\n",
      "(7, 209)\n",
      "(5, 209)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#grads =  L_model_backward(AL, Y, caches)\n",
    "#print(grads)\n",
    "#print(len(grads))\n",
    "\n",
    "#print(grads[\"dW1\"].shape)\n",
    "\n",
    "#print(parameters[\"W1\"].shape)\n",
    "\n",
    "#print(grads[\"db1\"].shape)\n",
    "#print(parameters[\"b1\"].shape)\n",
    "\n",
    "#print(grads[\"dW2\"].shape)\n",
    "#print(parameters[\"W2\"].shape)\n",
    "\n",
    "#print(grads[\"dW3\"].shape)\n",
    "#print(parameters[\"W3\"].shape)\n",
    "\n",
    "#print(grads[\"dW4\"].shape)\n",
    "#print(parameters[\"W4\"].shape)\n",
    "\n",
    "#print(grads[\"dA1\"].shape)\n",
    "#print(grads[\"dA2\"].shape)\n",
    "#print(grads[\"dA3\"].shape)\n",
    "#print(grads[\"dA4\"].shape)\n",
    "#print(grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters['W'+str(l+1)] - learning_rate*grads['dW'+str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters['b'+str(l+1)] - learning_rate*grads['db'+str(l+1)]\n",
    " \n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_layer_model\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "        #print(AL)\n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        #print(cost)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads =  L_model_backward(AL, Y, caches)\n",
    "        #print(grads)\n",
    "        ### END CODE HERE ###\n",
    " \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        #print(parameters)\n",
    "        ### END CODE HERE ###\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.771749\n",
      "Cost after iteration 100: 0.672053\n",
      "Cost after iteration 200: 0.648263\n",
      "Cost after iteration 300: 0.611507\n",
      "Cost after iteration 400: 0.567047\n",
      "Cost after iteration 500: 0.540138\n",
      "Cost after iteration 600: 0.527930\n",
      "Cost after iteration 700: 0.465477\n",
      "Cost after iteration 800: 0.369126\n",
      "Cost after iteration 900: 0.391747\n",
      "Cost after iteration 1000: 0.315187\n",
      "Cost after iteration 1100: 0.272700\n",
      "Cost after iteration 1200: 0.237419\n",
      "Cost after iteration 1300: 0.199601\n",
      "Cost after iteration 1400: 0.189263\n",
      "Cost after iteration 1500: 0.161189\n",
      "Cost after iteration 1600: 0.148214\n",
      "Cost after iteration 1700: 0.137775\n",
      "Cost after iteration 1800: 0.129740\n",
      "Cost after iteration 1900: 0.121225\n",
      "Cost after iteration 2000: 0.113821\n",
      "Cost after iteration 2100: 0.107839\n",
      "Cost after iteration 2200: 0.102855\n",
      "Cost after iteration 2300: 0.100897\n",
      "Cost after iteration 2400: 0.092878\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAFNCAYAAABvx4bHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBaeISIIUnCIiCfr/aYQFy31Q87sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x280f660a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2b40f10cf910>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c0db170caef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_mislabeled_images(classes, test_x, test_y, pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
